---
title: "Accelerating Token Generation with MTP (Multi-Token Prediction)"
tags:
- By MTC Team
- New Feature
excerpt: |
  Leveraging Multi-Token Prediction to optimize inference performance through efficient KV cache reuse and custom operators.
mathjax: true
---


### Custom MTP Operator

Due to our unique inference pattern, during the decode phase, adjacent sequences in the batch share the same KV cache, with the only difference being that sequence lengths increment progressively.

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/blogs/05-mtp/mtp.png"  style="zoom: 60%;" />
  <p style="font-family: sans-serif; font-size: 0.9em; color: #555;">During the decode phase, both sequences utilize KV cache for tokens t1, t2, t3, t4. The first sequence uses the first three caches, while the second sequence uses all four caches.</p>
</div>

When using standard attention operators, each sequence is computed independently, causing the same KV cache to be loaded repeatedly, resulting in significant waste. To eliminate this inefficiency and fully leverage the performance advantages of our MTP approach, we developed a custom MTP operator based on Flash Attention v3: [fa3_mtp](https://github.com/ModelTC/LightKernel/tree/main/flash-attention/hopper). This operator combines the queries (Q) of a group of sequences into a unified computation. During the $QK^T$ computation (where $Q$ is the query matrix and $K^T$ is the transpose of the key matrix), it dynamically sets the mask for the $Score$ matrix by calculating the seq_len corresponding to each q row.

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/blogs/05-mtp/fa3_mtp.png"  style="zoom: 60%;" />
  <p style="font-family: sans-serif; font-size: 0.9em; color: #555;">In the operator, masking is applied based on the sequence length corresponding to $t4$, setting the $Score$ matrix values to -INF.</p>
</div>

Through this approach, we achieve KV cache reuse with minimal overhead, enabling the attention operator to deliver up to *(mtp_step + 1)* Ã— speedup.

### Benchmark

Performance evaluation of the fa3_mtp operator:

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/blogs/05-mtp/fa3_mtp_benchmark.png"  style="zoom: 100%;" />
  <p style="font-family: sans-serif; font-size: 0.9em; color: #555;">Comprehensive performance comparison between FA3 and FA3_MTP operators (seqlen=8192, tp_q_head=16, tp=128). Left: Latency vs Batch Size showing FA3_MTP achieves consistently lower latency. Right: Throughput vs Batch Size demonstrating FA3_MTP delivers significantly higher throughput, with improvements becoming more substantial at larger batch sizes.</p>
</div>

Performance evaluation during the decode phase:

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/blogs/05-mtp/decode_benchmark.png"  style="zoom: 100%;" />
  <p style="font-family: sans-serif; font-size: 0.9em; color: #555;">Latency comparison between standard FA3 and FA3_MTP operators across different batch sizes (InputLen = 8192). FA3_MTP consistently achieves lower latency, with performance advantages becoming more pronounced at larger batch sizes.</p>
</div>
